# Gradient_Descent
Implementing gradient descent by myself

  This is the gradient descent implemented by me on some randomly taken data points on the graph and then finding a straight line passing through it by minimizing the cost (error) of our prediction. Gradient descent is actually a method to minimize the cost and is used more often in Machine Learning. In this case we are minimizing the cost of Linear regression.
    
  The main stuff is happening in the step_gradient() function. But in this case we are not using mini_batch method aur stochastic method which may improve our accuraccy a little bit, rather it is called a batch gradient descent. Moreover we are working on single feature only.
